# Документ дизайна агентной системы Orai

## 1. Требования

### 1.1 Цели проекта
Создать агентную систему на базе минималистичного фреймворка PocketFlow для обработки запросов пользователей через цепочку специализированных узлов.

### 1.2 Функциональные требования
- Получение и валидация входных данных от пользователя
- Анализ запросов через LLM
- Принятие решений на основе анализа
- Выполнение действий согласно принятым решениям
- Форматирование и вывод результатов

### 1.3 Нефункциональные требования
- Модульность: каждый узел отвечает за свою задачу
- Расширяемость: возможность добавления новых узлов
- Прозрачность: отслеживание истории обработки запроса
- Простота: минимальные зависимости (только pocketflow)

## 2. Дизайн потока (Flow Design)

### 2.1 Архитектура потока

```
[Пользователь]
      ↓
[InputNode] ──→ Получение запроса
      ↓
[AnalyzeNode] ──→ Анализ через LLM
      ↓
[DecisionNode] ──→ Принятие решения
      ↓
[ActionNode] ──→ Выполнение действия
      ↓
[OutputNode] ──→ Форматирование и вывод
      ↓
[Результат пользователю]
```

### 2.2 Паттерн проектирования
**Последовательный агентный поток (Sequential Agent Flow)**

Характеристики:
- Линейная последовательность узлов
- Каждый узел выполняется строго после предыдущего
- Данные передаются через общее хранилище (shared store)
- Отсутствие ветвлений и циклов (в базовой версии)

### 2.3 Обоснование выбора
Последовательный поток выбран для демонстрационной версии по следующим причинам:
- Простота понимания и отладки
- Чёткая структура обработки данных
- Возможность легко расширить до более сложных паттернов (с ветвлениями, циклами)
- Соответствие принципам PocketFlow

## 3. Структура данных (Data Design)

### 3.1 Shared Store (Общее хранилище)

Общее хранилище реализовано как словарь Python, содержащий:

```python
shared = {
    # Входные данные
    "user_input": str,          # Исходный запрос пользователя

    # Промежуточные результаты
    "analysis": str,            # Результат анализа запроса
    "decision": str,            # Принятое решение о действии
    "action_result": str,       # Результат выполнения действия

    # Метаданные
    "history": list[str],       # История обработки запроса
    "final_output": str,        # Финальный отформатированный результат
}
```

### 3.2 Контракт данных

#### InputNode → AnalyzeNode
- Записывает: `user_input`, `history`
- Читает: нет

#### AnalyzeNode → DecisionNode
- Записывает: `analysis`
- Читает: `user_input`

#### DecisionNode → ActionNode
- Записывает: `decision`
- Читает: `user_input`, `analysis`

#### ActionNode → OutputNode
- Записывает: `action_result`
- Читает: `user_input`, `analysis`, `decision`

#### OutputNode → End
- Записывает: `final_output`
- Читает: `user_input`, `action_result`, `history`

## 4. Дизайн узлов (Node Design)

### 4.1 Базовая структура узла

Каждый узел наследуется от `pocketflow.Node` и реализует три метода:

```python
class CustomNode(Node):
    def prep(self, shared):
        """Подготовка: чтение из shared store"""
        return data_for_exec

    def exec(self, prep_res):
        """Выполнение: основная логика узла"""
        return result

    def post(self, shared, prep_res, exec_res):
        """Постобработка: запись в shared store"""
        return "default"  # следующий узел
```

### 4.2 Описание узлов

#### InputNode
**Назначение:** Получение входных данных от пользователя

**Логика:**
- `prep()`: не используется (возвращает None)
- `exec()`: запрашивает ввод через `input()`
- `post()`: сохраняет `user_input` и инициализирует `history`

**Особенности:** Единственный узел с прямым взаимодействием с пользователем

#### AnalyzeNode
**Назначение:** Анализ запроса через LLM

**Логика:**
- `prep()`: извлекает `user_input`
- `exec()`: формирует промпт и вызывает `call_llm()`
- `post()`: сохраняет результат в `analysis`, добавляет запись в `history`

**Особенности:** Первый LLM вызов в цепочке

#### DecisionNode
**Назначение:** Принятие решения о дальнейших действиях

**Логика:**
- `prep()`: извлекает `user_input` и `analysis`
- `exec()`: формирует промпт для принятия решения, вызывает `call_llm()`
- `post()`: сохраняет `decision`, обновляет `history`

**Особенности:** Использует контекст из предыдущего анализа

#### ActionNode
**Назначение:** Выполнение действия на основе решения

**Логика:**
- `prep()`: извлекает `user_input`, `analysis`, `decision`
- `exec()`: формирует финальный промпт и получает результат от LLM
- `post()`: сохраняет `action_result`, обновляет `history`

**Особенности:** Самый "умный" узел с полным контекстом

#### OutputNode
**Назначение:** Форматирование и вывод результата

**Логика:**
- `prep()`: извлекает `user_input`, `action_result`, `history`
- `exec()`: форматирует финальный вывод
- `post()`: сохраняет `final_output`, выводит результат на экран

**Особенности:** Единственный узел с side-effect (вывод на экран)

## 5. Утилиты (Utilities)

### 5.1 call_llm()

**Файл:** `utils/call_llm.py`

**Назначение:** Абстракция для вызова LLM API

**Текущая реализация:** Mock-версия для демонстрации

**Будущая реализация:** Интеграция с реальными LLM:
- OpenAI GPT-4
- Anthropic Claude
- Локальные модели (Ollama)
- Другие провайдеры

**Интерфейс:**
```python
def call_llm(prompt: str, model: str = "mock", temperature: float = 0.7) -> str:
    """Вызов LLM с заданным промптом"""
```

### 5.2 Дополнительные утилиты (планируемые)

- `validate_prompt()`: Валидация промптов перед отправкой
- `format_prompt()`: Форматирование промптов по шаблонам
- `cache_response()`: Кеширование ответов LLM
- `log_interaction()`: Логирование взаимодействий

## 6. Реализация (Implementation)

### 6.1 Структура проекта

```
orai/
├── main.py              # Точка входа
├── nodes.py             # Определения узлов
├── flow.py              # Создание потоков
├── utils/
│   ├── __init__.py
│   └── call_llm.py      # LLM утилиты
├── docs/
│   └── design.md        # Этот документ
├── pyproject.toml       # Метаданные проекта
├── requirements.txt     # Зависимости
├── CLAUDE.md            # Руководство для Claude Code
└── README.md            # Документация проекта
```

### 6.2 Зависимости

Минимальные зависимости:
- `pocketflow>=0.0.1` - ядро фреймворка

Будущие зависимости (опционально):
- `openai` или `anthropic` - для интеграции с LLM
- `python-dotenv` - для управления конфигурацией
- `loguru` - для улучшенного логирования

### 6.3 Принципы разработки

1. **Separation of Concerns:** Каждый узел отвечает за одну задачу
2. **Single Responsibility:** Узлы не должны знать о существовании других узлов
3. **Data Contract:** Явный контракт данных через shared store
4. **Fail-Fast:** Ошибки должны быть видны сразу
5. **Comments in Russian:** Все комментарии на русском языке

## 7. Оптимизация (Optimization)

### 7.1 Текущие оптимизации

- Минимальные зависимости (только PocketFlow)
- Простая структура потока
- Mock LLM для быстрого тестирования

### 7.2 Планируемые оптимизации

1. **Prompt Engineering:**
   - Улучшение промптов для каждого узла
   - A/B тестирование различных формулировок
   - Добавление few-shot примеров

2. **Кеширование:**
   - Кеширование повторяющихся запросов
   - Сохранение контекста сессии

3. **Параллелизация:**
   - Параллельный запуск независимых узлов (если появятся)

4. **Мониторинг:**
   - Логирование времени выполнения каждого узла
   - Трекинг успешности запросов

## 8. Надёжность (Reliability)

### 8.1 Текущие механизмы

- Обработка `KeyboardInterrupt` в main.py
- Общий `try-except` блок для отлова ошибок

### 8.2 Планируемые улучшения

1. **Retry механизмы:**
   - Автоматические повторы при сбоях LLM API
   - Экспоненциальная задержка между попытками

2. **Валидация:**
   - Проверка входных данных
   - Валидация ответов LLM

3. **Логирование:**
   - Детальные логи всех операций
   - Сохранение истории запросов

4. **Self-evaluation:**
   - Узлы для проверки качества ответов
   - Автоматическая коррекция при низком качестве

## 9. Расширение системы

### 9.1 Добавление новых узлов

Для добавления нового узла:

1. Создать класс в `nodes.py`, наследующий `Node`
2. Реализовать методы `prep()`, `exec()`, `post()`
3. Обновить поток в `flow.py`
4. Документировать контракт данных

### 9.2 Добавление ветвлений

Для создания условных ветвлений:

```python
def post(self, shared, prep_res, exec_res):
    if condition:
        return "action_a"  # переход к узлу action_a
    else:
        return "action_b"  # переход к узлу action_b
```

### 9.3 Добавление циклов

Для создания циклических потоков:

```python
def post(self, shared, prep_res, exec_res):
    iteration = shared.get("iteration", 0)
    if iteration < max_iterations:
        shared["iteration"] = iteration + 1
        return "repeat"  # возврат к предыдущему узлу
    else:
        return "default"  # продолжение потока
```

## 10. Заключение

Агентная система Orai демонстрирует базовую архитектуру для создания LLM-приложений на базе PocketFlow. Система спроектирована с учётом:

- **Простоты:** Минимальные зависимости, чёткая структура
- **Расширяемости:** Легко добавлять новые узлы и возможности
- **Прозрачности:** Вся логика видна и понятна
- **Практичности:** Готова к интеграции с реальными LLM

Следующие шаги:
1. Интеграция с реальным LLM API
2. Добавление более сложных паттернов обработки
3. Реализация системы кеширования и логирования
4. Создание веб-интерфейса или API
